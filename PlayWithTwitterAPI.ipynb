{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json #permite trabajar y serializar archivos con formato .json\n",
    "import pandas as pd # trabajos con series y dataframes, análisis de datos\n",
    "import re #expresiones regulares\n",
    "from datetime import datetime #manupulación de fecha\n",
    "from dateutil.parser import parse #manipulación de fechas\n",
    "\n",
    "#listado de ficheros\n",
    "files = [\"data-twitter-1000.dat\",\"data-twitter-1001.dat\",\"data-twitter-1002.dat\",\n",
    "           \"data-twitter-1003.dat\",\"data-twitter-1004.dat\",\"data-twitter-1005.dat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "##### Transforme la fecha de todos los tweets a formato AAAAMMDD MM:SS y envíe los resultados en formato CSV con los campos: id, fecha (modificada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformated_list = []\n",
    "\n",
    "# carga archivo desde array declarado al inicio (listado de ficheros).\n",
    "for file in files:\n",
    "    with open(file, 'r') as fh:\n",
    "        \n",
    "        # apertura del archivo y lectura línea por línea para consumir json.\n",
    "        for line in fh:\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # transformación de fechas\n",
    "            transformated_list_tmp = [tweet['id'],parse(tweet['created_at']).strftime(\"%Y%m%d %M:%S\")]\n",
    "\n",
    "            transformated_list.append(transformated_list_tmp)\n",
    "\n",
    "transformated_df = pd.DataFrame(transformated_list,columns=[\"id\",\"fecha\"])\n",
    "\n",
    "# generación de archivo de salida csv\n",
    "transformated_df.to_csv('output_1.csv',index = False)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "##### Identifique, mediante expresiones regulares, las URLs contenidas en el cuerpo de los tweets y presente un ranking de las 15 URLs más mencionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "\n",
    "# carga archivo desde array declarado al inicio (listado de ficheros).\n",
    "for file in files:\n",
    "    \n",
    "    # apertura del archivo y lectura línea por línea para consumir json.\n",
    "    with open(file, 'r') as fh:\n",
    "        for line in fh:\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # Separa cada palabra como una nueva línea.\n",
    "            for word in tweet[\"text\"].split():\n",
    "                \n",
    "                # Busqueda de urls por regular expressions\n",
    "                find = re.search(\"(http://.*)\",word)\n",
    "               \n",
    "                if find != None:\n",
    "                    text_list.append(find.group(1))\n",
    "             \n",
    "df = pd.DataFrame(text_list,columns=[\"url\"])\n",
    "\n",
    "# Agrupación de urls y conteo por grupos\n",
    "group_url = df.groupby(\"url\")[\"url\"].count().reset_index(name='conteo')\n",
    "\n",
    "# ordena urls de forma descendente\n",
    "url_ordered = group_url.sort_values(by='conteo',ascending=False)\n",
    "\n",
    "# top 15 de urls mas mencionadas en los tweets\n",
    "ranking = url_ordered.head(15)\n",
    "\n",
    "# generación de archivo de salida csv\n",
    "ranking.to_csv('output_2.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "##### Presente un listado de hashtags ordenados de mayor a menor por cantidad de apariciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_list = []\n",
    "\n",
    "# carga archivo desde array declarado al inicio (listado de ficheros).\n",
    "for file in files:\n",
    "    # apertura del archivo y lectura línea por línea para consumir json.\n",
    "    with open(file,'r') as fh:\n",
    "        for line in fh:\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # si el largo de la lista es mayor a cero,guarda el registro en una lista\n",
    "            if len(tweet[\"entities\"][\"hashtags\"])>0:               \n",
    "                muestra = tweet[\"entities\"][\"hashtags\"][0][\"text\"]\n",
    "                hashtags_list.append(muestra)\n",
    "\n",
    "# creación de dataframe con datos provenientes de una lista.\n",
    "hashtags_df = pd.DataFrame(hashtags_list,columns=[\"hashtag\"])  \n",
    "\n",
    "# agrupación de hashtags y conteo sobre los grupos.\n",
    "hashtags_appearances = hashtags_df.groupby(\"hashtag\")[\"hashtag\"].count().reset_index(name=\"total_apariciones\")\n",
    "\n",
    "# ordenar hashtags con número total de apariciones.\n",
    "hashtags_ordered = hashtags_appearances.sort_values(by='total_apariciones',ascending=False) \n",
    "\n",
    "# generación de archivo de salida csv.\n",
    "hashtags_ordered.to_csv('output_3.csv',encoding='utf-8',index=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "##### Transforme la data de usuario (user) de todo el dataset a formato estructurado y preséntelo en un solo archivo CSV con codificación UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as fh:\n",
    "\n",
    "        for line in fh:\n",
    "            \n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # creacion de estructura de datos de Usuario.\n",
    "            users_list2 = [  \n",
    "            tweet[\"user\"][\"id\"],\n",
    "            tweet[\"user\"][\"id_str\"],\n",
    "            tweet[\"user\"][\"name\"],\n",
    "            tweet[\"user\"][\"screen_name\"],\n",
    "            tweet[\"user\"][\"location\"],\n",
    "            tweet[\"user\"][\"url\"],\n",
    "            tweet[\"user\"][\"description\"],\n",
    "            tweet[\"user\"][\"verified\"],\n",
    "            tweet[\"user\"][\"followers_count\"],\n",
    "            tweet[\"user\"][\"friends_count\"],\n",
    "            tweet[\"user\"][\"listed_count\"],\n",
    "            tweet[\"user\"][\"favourites_count\"],\n",
    "            tweet[\"user\"][\"statuses_count\"],\n",
    "            tweet[\"user\"][\"created_at\"],\n",
    "            tweet[\"user\"][\"utc_offset\"],\n",
    "            tweet[\"user\"][\"time_zone\"],\n",
    "            tweet[\"user\"][\"geo_enabled\"],\n",
    "            tweet[\"user\"][\"lang\"],\n",
    "            tweet[\"user\"][\"profile_image_url_https\"]\n",
    "            ]\n",
    "            users_list.append(users_list2)\n",
    "\n",
    "users_df = pd.DataFrame(users_list,columns=[\"id\",\"id_str\",\"name\",\"screen_name\",\"location\",\"url\",\n",
    "\"description\",\"verified\",\"followers_count\",\"friends_count\",\"listed_count\",\"favourites_count\",\n",
    "\"statuses_count\",\"created_at\",\"utc_offset\",\"time_zone\",\"geo_enabled\",\"lang\",\"profile_image_url_https\"])\n",
    "\n",
    "# generación de archivo de salida csv\n",
    "users_df.to_csv('output_4.csv',encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "##### Presente el contenido de los tweets más retweeteados en orden descendente, en archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_list = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as fh:\n",
    "\n",
    "        for line in fh:\n",
    "            tweet = json.loads(line)\n",
    "            retweet_list2 = [\n",
    "               tweet[\"text\"],\n",
    "               tweet[\"retweet_count\"] #retweet_count\n",
    "            ]\n",
    "            \n",
    "            retweet_list.append(retweet_list2)\n",
    "\n",
    "retweet_df = pd.DataFrame(retweet_list,columns=[\"tweet_text\",\"retweet_count\"])\n",
    "\n",
    "# ordenar conteo de tweets deforma descendente.\n",
    "retweet_df.sort_values(by=[\"retweet_count\"],ascending=False)\n",
    "\n",
    "# generación de archivo de salida csv\n",
    "retweet_df.to_csv('output_5.csv',encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
